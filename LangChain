A normal ML mein pattern identify hota hai within the given data
classification problem ki mail spam hai ya ni......ya recommendation system Jahan

1. A normal chatbot which is built using LLM - doesn't have memory and is not autonomous
2. The chatbot improved with RAG - means the chatbot will provide answer from the shared set of files...but again no memory and not autonomous
3. Agentic AI Chatbot - give the goal ...it will take initiatives and ask for approvals...if it is integrated with certain tools(api) it can automate quite few things
 --> Generative AI is a building block of Agentic AI


#################
LANGCHAIN

-> open source framework to build LLM based apps 
-> similar frameworks are haystacks and llamaindex
-> so initially if we use gemini and once created we need to change the model to openai or change the cloud service from aws to gcp so very minimal 
code changes are required
-> using langchains u can interact with language models (LLM - text input ...output is also text) and embedding models(text as input...vector as output...
used mostly for semantic search Jahan pe embeddings rehte means vectors)
-> LLM API calls are stateless


-> 6 diff components - models,prompts,chains,memory,indexes,agents

-> models: core interfaces through which you interact with AI Models.....sabhi LLm models ke API ko use karne ka tareeka diff hai toh yeh langchain ka interface hai Jahan se har ek AI model se standard way se interaction possible hai

models are of 2 types : language and embedding
language models are of 2 types: LLM and chat models
LLM : general purpose models that is used for raw text generation. They take a string or plain text as input and return a string.
Chat Models: specialised for conversational tasks. They take sequence of messages as inputs and return chat messages as output

-> chains : to build pipeline...automatically gets the output from step 1 and gives it to step 2
parallel chain ( input ko parallel alag alag LLm mein dena) , conditional chains (based on conditions LLM usko execute karega)

-> indexes: connect ur apps to external knowledge - such as PDF,website or DB
these 4 things make up the indexes - doc loader, text splitter, vector store, retrievers

Pehle load kiya...unko chunks mein divide kiya...embeddings mein convert kiya ...then storing the vectors...then retrieving it as per the user query...
toh user query bhi embeddings mein convert hota hai...Jahan pe vectors match hote hai who retrieve hota hai

-> memory
ConversationBufferMemory : stores a transcript of recent mssgs. Great for short chats but can grow largely
ConversationBufferWindowMemory: only keeps the last N interactions to avoid excessive token usage
SummariserBasedMemory: periodically summarises older chat segment to keep a condensed memory footprint
CustomMemory: for advanced use cases, you can store specialised state


==> langchain mein LLM use karke
from langchain_openai import OpenAI
from dotenv import load_dotenv
load_dotenv()
llm = OpenAI(model='gpt-3.5-turbo-instruct')
result = llm.invoke("What is the capital of India")
print(result)


==> langchain mein ChatModels use karke

from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
load_dotenv()
model = ChatOpenAI(model='gpt-4', temperature=1.5, max_completion_tokens=10)
result = model.invoke("Write a 5 line poem on cricket")
print(result.content)

from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
load_dotenv()
model = ChatGoogleGenerativeAI(model='gemini-1.5-pro')
result = model.invoke('What is the capital of India')
print(result.content)

-> HuggingFace mein API use karke open source models call karte hue
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint
from dotenv import load_dotenv
load_dotenv()
llm = HuggingFaceEndpoint(
    repo_id="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    task="text-generation"
)
model = ChatHuggingFace(llm=llm)
result = model.invoke("What is the capital of India")
print(result.content)


NOTE : .env file mein joh variables use karna hai for API KEY woh fixed hai
OPENAI_API_KEY, GOOGLE_API_KEY, ANTHROPIC_API_KEY, HUGGINGFACEHUB_ACCESS_TOKEN
tabhi hi jabh hum from dotenv import load_dotenv karenge toh api keys dhang se load honge



-> Agents
LLM with reasoning capabilities and tools ka access






Terms
- prompt engineering
- RLHF
- RAG
